"""
æ™ºèƒ½é¢è¯•é—®é¢˜ç”Ÿæˆå™¨
å®Œå…¨åŸºäºæ˜Ÿç«å¤§æ¨¡å‹ï¼ŒåƒçœŸæ­£é¢è¯•å®˜ä¸€æ ·æ ¹æ®ç®€å†ã€å²—ä½è¦æ±‚å’Œå¯¹è¯å†å²åŠ¨æ€ç”Ÿæˆé—®é¢˜
"""
from typing import Dict, List, Optional
from app.core.spark_llm import SparkLLM
from langchain_core.messages import HumanMessage
from app.utils.json_helper import JSONHelper
import json
import re
from app.utils.logger import interview_generator_logger

class EnhancedInterviewGenerator:
    def __init__(self, spark_config: Dict):
        self.llm = SparkLLM(
            app_id=spark_config.get("app_id", ""),
            api_key=spark_config.get("api_key", ""),
            api_secret=spark_config.get("api_secret", ""),
            spark_url=spark_config.get("spark_url", "wss://spark-api.xf-yun.com/v3.5/chat"),
            domain=spark_config.get("domain", "generalv3.5"),
            temperature=0.7
        )
    

    

    
    def generate_next_question(self, candidate_info: Dict, job_info: Dict, 
                             conversation_history: List = None, 
                             current_round: int = 1,
                             resume_context: List[str] = None,
                             job_context: List[str] = None) -> Dict:
        """ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜"""
        prompt = self._build_interviewer_prompt(
            candidate_info, job_info, conversation_history, current_round,
            resume_context, job_context
        )
        
        print(f"ğŸ¤– é¢è¯•å®˜æ­£åœ¨æ€è€ƒç¬¬{current_round}ä¸ªé—®é¢˜...")
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        # ä½¿ç”¨ç»Ÿä¸€çš„JSONè§£ææ–¹æ³•
        question_data = JSONHelper.parse_llm_response(response.content, "é—®é¢˜ç”Ÿæˆ")
        
        if not question_data:
            raise ValueError(f"é—®é¢˜ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return question_data
    
    def should_follow_up(self, last_question: str, candidate_answer: str, 
                        resume_context: List[str] = None, 
                        job_context: List[str] = None) -> Dict:
        """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®"""
        prompt = self._build_follow_up_decision_prompt(
            last_question, candidate_answer, resume_context, job_context
        )
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        decision_data = JSONHelper.parse_llm_response(response.content, "è¿½é—®åˆ¤æ–­")
        
        if not decision_data:
            raise ValueError(f"è¿½é—®åˆ¤æ–­å¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return decision_data
    
    def generate_follow_up_question(self, last_question: str, candidate_answer: str,
                                   follow_up_focus: str, resume_context: List[str] = None,
                                   job_context: List[str] = None) -> Dict:
        """ç”Ÿæˆè¿½é—®é—®é¢˜"""
        prompt = self._build_follow_up_question_prompt(
            last_question, candidate_answer, follow_up_focus, resume_context, job_context
        )
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        question_data = JSONHelper.parse_llm_response(response.content, "è¿½é—®ç”Ÿæˆ")
        
        if not question_data:
            raise ValueError(f"è¿½é—®ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return question_data
    
    def _build_interviewer_prompt(self, candidate_info: Dict, job_info: Dict, 
                                 conversation_history: List, current_round: int,
                                 resume_context: List[str] = None,
                                 job_context: List[str] = None) -> str:
        """æ„å»ºé¢è¯•å®˜è§’è‰²æç¤ºè¯"""
        history_summary = self._summarize_conversation_history(conversation_history)
        interview_stage = self._determine_interview_stage(current_round, conversation_history)
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯é¢è¯•å®˜ï¼Œæ­£åœ¨é¢è¯•ä¸€ä½å€™é€‰äººã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜ï¼š

## å€™é€‰äººç®€å†ä¿¡æ¯ï¼š
{json.dumps(candidate_info, ensure_ascii=False, indent=2)}

## å²—ä½è¦æ±‚ï¼š
{json.dumps(job_info, ensure_ascii=False, indent=2)}

## ğŸ“‹ ç‰¹åˆ«æé†’ï¼š
{self._get_smart_interview_guidance(current_round, conversation_history, job_info)}

{context_info}

## é¢è¯•è¿›å±•ï¼š
- å½“å‰æ˜¯ç¬¬{current_round}ä¸ªé—®é¢˜
- é¢è¯•é˜¶æ®µï¼š{interview_stage}

## å¯¹è¯å†å²æ‘˜è¦ï¼š
{history_summary}

## é¢è¯•å®˜æŒ‡å¯¼åŸåˆ™ï¼š
1. **æ™ºèƒ½é˜¶æ®µåˆ¤æ–­**ï¼šæ ¹æ®å¯¹è¯å†å²å’Œå€™é€‰äººå›ç­”è´¨é‡ï¼Œæ™ºèƒ½åˆ¤æ–­å½“å‰åº”è¯¥é—®åŸºç¡€çŸ¥è¯†è¿˜æ˜¯é¡¹ç›®ç»éªŒ
2. **åŸºç¡€ä¼˜å…ˆ**ï¼šåœ¨æ·±å…¥é¡¹ç›®ä¹‹å‰ï¼Œå…ˆéªŒè¯å²—ä½æ ¸å¿ƒæŠ€èƒ½çš„åŸºç¡€çŸ¥è¯†
3. **åˆ©ç”¨æ£€ç´¢ä¸Šä¸‹æ–‡**ï¼šä¼˜å…ˆåŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³ç®€å†ç‰‡æ®µå’Œå²—ä½è¦æ±‚è¿›è¡Œæé—®
4. **åƒçœŸæ­£é¢è¯•å®˜ä¸€æ ·æ€è€ƒ**ï¼šè€ƒè™‘å€™é€‰äººçš„èƒŒæ™¯ã€å²—ä½è¦æ±‚å’Œå·²ç»äº†è§£çš„ä¿¡æ¯
5. **å¾ªåºæ¸è¿›**ï¼šå…ˆåŸºç¡€çŸ¥è¯†ï¼Œå†é¡¹ç›®ç»éªŒï¼Œæœ€åæ·±åº¦æ€ç»´
6. **æœ‰é’ˆå¯¹æ€§**ï¼šåŸºäºå²—ä½è¦æ±‚çš„æ ¸å¿ƒæŠ€èƒ½è¿›è¡Œé‡ç‚¹æé—®
7. **é¿å…é‡å¤**ï¼šä¸è¦é—®å·²ç»è®¨è®ºè¿‡çš„å†…å®¹
8. **è‡ªç„¶è¿‡æ¸¡**ï¼šé—®é¢˜è¦ç¬¦åˆé¢è¯•å¯¹è¯çš„è‡ªç„¶æµç¨‹
9. **æ·±åº¦æŒ–æ˜**ï¼šå¦‚æœæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ï¼Œè¦æ·±å…¥è¯¢é—®å…·ä½“ç»†èŠ‚
10. **çµæ´»è°ƒæ•´**ï¼šå¦‚æœå€™é€‰äººåŸºç¡€æ‰å®ï¼Œå¯ä»¥æå‰è¿›å…¥é¡¹ç›®é˜¶æ®µï¼›å¦‚æœåŸºç¡€è–„å¼±ï¼Œç»§ç»­å·©å›ºåŸºç¡€çŸ¥è¯†

## é¢è¯•æµç¨‹ç­–ç•¥ï¼ˆè½¯çº¦æŸï¼Œçµæ´»è°ƒæ•´ï¼‰ï¼š

### ç¬¬ä¸€ä¸ªé—®é¢˜å›ºå®šè¦æ±‚ï¼š
ç¬¬ä¸€ä¸ªé—®é¢˜å¿…é¡»æ˜¯è‡ªæˆ‘ä»‹ç»ï¼Œä¾‹å¦‚ï¼š
- "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨è‡ªå·±ï¼ŒåŒ…æ‹¬æ‚¨çš„æŠ€æœ¯èƒŒæ™¯å’Œå·¥ä½œç»å†"
- "èƒ½å¦è¯·æ‚¨å…ˆåšä¸ªè‡ªæˆ‘ä»‹ç»ï¼Œé‡ç‚¹è¯´è¯´æ‚¨çš„æŠ€æœ¯ç»éªŒ"
- "æˆ‘ä»¬å…ˆä»è‡ªæˆ‘ä»‹ç»å¼€å§‹å§ï¼Œè¯·è°ˆè°ˆæ‚¨çš„ä¸“ä¸šèƒŒæ™¯å’ŒæŠ€æœ¯ç‰¹é•¿"

### åç»­é—®é¢˜æ™ºèƒ½ç­–ç•¥ï¼š
é¢è¯•å®˜åº”è¯¥æ ¹æ®å¯¹è¯è¿›å±•å’Œå€™é€‰äººå›ç­”è´¨é‡ï¼Œçµæ´»é€‰æ‹©é—®é¢˜ç±»å‹ï¼š

**é˜¶æ®µ1 - åŸºç¡€ä¸“ä¸šçŸ¥è¯†éªŒè¯ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰ï¼š**
- å…ˆéªŒè¯å²—ä½è¦æ±‚çš„æ ¸å¿ƒæŠ€èƒ½å’ŒåŸºç¡€çŸ¥è¯†
- é—®ä¸€äº›è¯¥å²—ä½å¿…é¡»æŒæ¡çš„åŸºæœ¬æ¦‚å¿µå’ŒæŠ€æœ¯
- ç¡®ä¿å€™é€‰äººå…·å¤‡åŸºç¡€çš„ä¸“ä¸šç´ å…»
- ä¾‹å¦‚ï¼šç®—æ³•åŸºç¡€ã€ç¼–ç¨‹è¯­è¨€ç‰¹æ€§ã€åŸºæœ¬æ¶æ„æ¦‚å¿µç­‰

**é˜¶æ®µ2 - é¡¹ç›®ç»éªŒæ·±å…¥ï¼ˆåœ¨åŸºç¡€éªŒè¯åï¼‰ï¼š**
- å½“å€™é€‰äººå±•ç¤ºäº†è¶³å¤Ÿçš„åŸºç¡€çŸ¥è¯†åï¼Œå†æ·±å…¥é¡¹ç›®ç»éªŒ
- è¯¢é—®é¡¹ç›®çš„æŠ€æœ¯å®ç°ç»†èŠ‚ã€é‡åˆ°çš„æŒ‘æˆ˜ã€è§£å†³æ–¹æ¡ˆ
- éªŒè¯ç†è®ºçŸ¥è¯†åœ¨å®é™…é¡¹ç›®ä¸­çš„åº”ç”¨èƒ½åŠ›
- äº†è§£å€™é€‰äººçš„é¡¹ç›®è´¡çŒ®å’ŒæŠ€æœ¯æˆé•¿

**é˜¶æ®µ3 - æ·±åº¦æ€ç»´è€ƒå¯Ÿï¼š**
- è€ƒå¯Ÿè§£å†³é—®é¢˜çš„æ€è·¯å’Œæ–¹æ³•
- äº†è§£å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”èƒ½åŠ›
- è¯„ä¼°æŠ€æœ¯è§†é‡å’Œå‘å±•æ½œåŠ›

**æ™ºèƒ½åˆ¤æ–­åŸåˆ™ï¼š**
- å¦‚æœå€™é€‰äººåŸºç¡€çŸ¥è¯†å›ç­”å¾—ä¸å¤Ÿå¥½ï¼Œç»§ç»­é—®åŸºç¡€é—®é¢˜ï¼Œæš‚ä¸è¿›å…¥é¡¹ç›®é˜¶æ®µ
- å¦‚æœå€™é€‰äººå±•ç¤ºäº†æ‰å®çš„åŸºç¡€ï¼Œå¯ä»¥æå‰è¿›å…¥é¡¹ç›®ç»éªŒé˜¶æ®µ
- æ ¹æ®å²—ä½è¦æ±‚çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä¼˜å…ˆéªŒè¯æœ€é‡è¦çš„åŸºç¡€çŸ¥è¯†
- ä¸è¦æ­»æ¿åœ°æŒ‰è½®æ¬¡æ‰§è¡Œï¼Œè¦æ ¹æ®å€™é€‰äººçš„å®é™…è¡¨ç°çµæ´»è°ƒæ•´

è¯·ç›´æ¥è¿”å›çº¯JSONæ ¼å¼çš„é¢è¯•é—®é¢˜ï¼Œä¸è¦åŒ…å«ä»»ä½•ä»£ç å—æ ‡è®°ã€è§£é‡Šæˆ–æ€è€ƒè¿‡ç¨‹ï¼š

{{
    "type": "context_enhanced_question",
    "category": "é—®é¢˜ç±»åˆ«ï¼ˆå¦‚ï¼šæŠ€èƒ½éªŒè¯ã€é¡¹ç›®ç»éªŒã€æ€ç»´æ–¹å¼ç­‰ï¼‰",
    "question": "å…·ä½“é—®é¢˜å†…å®¹ï¼ˆè¦è‡ªç„¶ã€ä¸“ä¸šï¼Œä¼˜å…ˆåŸºäºæ£€ç´¢ä¸Šä¸‹æ–‡ï¼‰",
    "focus": "è€ƒå¯Ÿé‡ç‚¹",
    "expected_depth": "æœŸæœ›å›ç­”æ·±åº¦ï¼ˆbasic/medium/highï¼‰",
    "interviewer_thinking": "é¢è¯•å®˜çš„æ€è€ƒé€»è¾‘ï¼ˆä¸ºä»€ä¹ˆé—®è¿™ä¸ªé—®é¢˜ï¼‰",
    "context_used": "æ˜¯å¦ä½¿ç”¨äº†æ£€ç´¢ä¸Šä¸‹æ–‡ï¼ˆtrue/falseï¼‰"
}}
"""
    
    def _build_follow_up_decision_prompt(self, last_question: str, candidate_answer: str,
                                       resume_context: List[str] = None,
                                       job_context: List[str] = None) -> str:
        """æ„å»ºè¿½é—®åˆ¤æ–­æç¤ºè¯"""
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é¢è¯•å®˜ã€‚è¯·åˆ†æå€™é€‰äººçš„å›ç­”ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè¿½é—®ã€‚

é—®é¢˜ï¼š{last_question}

å€™é€‰äººå›ç­”ï¼š{candidate_answer}

{context_info}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®ï¼š

**éœ€è¦è¿½é—®çš„æƒ…å†µï¼š**
1. å›ç­”è¿‡äºç®€çŸ­æˆ–ç¬¼ç»Ÿï¼Œç¼ºä¹å…·ä½“ç»†èŠ‚
2. æåˆ°äº†æœ‰è¶£çš„æŠ€æœ¯ç‚¹ä½†æ²¡æœ‰æ·±å…¥è§£é‡Š
3. å›ç­”ä¸­æœ‰ä¸“ä¸šæœ¯è¯­ä½†æ²¡æœ‰å±•ç¤ºçœŸæ­£ç†è§£
4. æåˆ°äº†é¡¹ç›®æˆ–ç»éªŒä½†ç¼ºå°‘å…·ä½“æ•°æ®å’Œæˆæœ
5. å›ç­”ä¸ç®€å†ä¿¡æ¯ä¸ä¸€è‡´ï¼Œéœ€è¦æ¾„æ¸…
6. æ¶‰åŠå²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼Œå€¼å¾—æ·±å…¥äº†è§£

**ä¸éœ€è¦è¿½é—®çš„æƒ…å†µï¼š**
1. å›ç­”è¯¦ç»†å……åˆ†ï¼Œå·²ç»å±•ç¤ºäº†ç›¸å…³èƒ½åŠ›
2. å·²ç»è¿ç»­è¿½é—®2æ¬¡ä»¥ä¸ŠåŒä¸€è¯é¢˜
3. å›ç­”ä¸å²—ä½è¦æ±‚å…³è”åº¦è¾ƒä½
4. å€™é€‰äººæ˜æ˜¾å¯¹è¯¥è¯é¢˜ä¸ç†Ÿæ‚‰ï¼Œç»§ç»­è¿½é—®æ„ä¹‰ä¸å¤§
5. å€™é€‰äººæ˜ç¡®è¡¨ç¤ºä¸æƒ³å›ç­”è¿™ä¸ªé—®é¢˜

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "should_follow_up": true/false,
    "reason": "åˆ¤æ–­åŸå› ",
    "follow_up_focus": "å¦‚æœéœ€è¦è¿½é—®ï¼Œé‡ç‚¹å…³æ³¨ä»€ä¹ˆæ–¹é¢",
    "confidence": "high/medium/low",
    "suggested_direction": "å»ºè®®çš„è¿½é—®æ–¹å‘æˆ–ä¸‹ä¸€ä¸ªè¯é¢˜æ–¹å‘"
}}
"""
    
    def _build_follow_up_question_prompt(self, last_question: str, candidate_answer: str,
                                       follow_up_focus: str, resume_context: List[str] = None,
                                       job_context: List[str] = None) -> str:
        """æ„å»ºè¿½é—®é—®é¢˜æç¤ºè¯"""
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é¢è¯•å®˜ï¼Œéœ€è¦åŸºäºå€™é€‰äººçš„å›ç­”ç”Ÿæˆä¸€ä¸ªç²¾å‡†çš„è¿½é—®ã€‚

åŸé—®é¢˜ï¼š{last_question}

å€™é€‰äººå›ç­”ï¼š{candidate_answer}

è¿½é—®é‡ç‚¹ï¼š{follow_up_focus}

{context_info}

è¯·ç”Ÿæˆä¸€ä¸ªè‡ªç„¶ã€æœ‰é’ˆå¯¹æ€§çš„è¿½é—®é—®é¢˜ï¼Œè¦æ±‚ï¼š
1. åŸºäºå€™é€‰äººåˆšæ‰çš„å›ç­”å†…å®¹
2. æŒ–æ˜æ›´æ·±å±‚çš„æŠ€æœ¯ç»†èŠ‚æˆ–å®è·µç»éªŒ
3. éªŒè¯å€™é€‰äººçš„çœŸå®ç†è§£ç¨‹åº¦
4. ä¿æŒé¢è¯•å¯¹è¯çš„è‡ªç„¶æµç•…
5. å¦‚æœæœ‰ç®€å†ä¿¡æ¯ï¼Œå¯ä»¥ç»“åˆç®€å†å†…å®¹è¿›è¡ŒéªŒè¯

è¿”å›JSONæ ¼å¼ï¼š
{{
    "type": "follow_up_question",
    "category": "è¿½é—®ç±»åˆ«",
    "question": "å…·ä½“çš„è¿½é—®é—®é¢˜",
    "focus": "è€ƒå¯Ÿé‡ç‚¹",
    "expected_depth": "æœŸæœ›å›ç­”æ·±åº¦ï¼ˆbasic/medium/highï¼‰",
    "interviewer_thinking": "é¢è¯•å®˜çš„æ€è€ƒé€»è¾‘",
    "follow_up_level": "ç¬¬å‡ å±‚è¿½é—®ï¼ˆfirst/second/thirdï¼‰"
}}
"""
    
    def _build_context_info(self, resume_context: List[str] = None, 
                           job_context: List[str] = None) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_info = ""
        if resume_context and len(resume_context) > 0:
            context_info += f"""
## ğŸ” ç›¸å…³ç®€å†ç‰‡æ®µï¼ˆåŸºäºå¯¹è¯æ£€ç´¢ï¼‰ï¼š
{chr(10).join([f"- {ctx}" for ctx in resume_context])}
"""
        
        if job_context and len(job_context) > 0:
            context_info += f"""
## ğŸ¯ ç›¸å…³å²—ä½è¦æ±‚ï¼ˆåŸºäºå¯¹è¯æ£€ç´¢ï¼‰ï¼š
{chr(10).join([f"- {ctx}" for ctx in job_context])}
"""
        return context_info
    
    def _summarize_conversation_history(self, conversation_history: List) -> str:
        """ç”Ÿæˆå¯¹è¯å†å²æ‘˜è¦"""
        if not conversation_history:
            return "è¿™æ˜¯é¢è¯•çš„å¼€å§‹ï¼Œè¿˜æ²¡æœ‰å¯¹è¯å†å²ã€‚"
        
        topics_discussed = []
        for item in conversation_history:
            if isinstance(item, dict):
                if "category" in item:
                    topics_discussed.append(item["category"])
                elif "question" in item:
                    keywords = self._extract_keywords_from_question(item["question"])
                    topics_discussed.extend(keywords)
        
        if topics_discussed:
            unique_topics = list(set(topics_discussed))
            return f"å·²ç»è®¨è®ºçš„è¯é¢˜ï¼š{', '.join(unique_topics[:5])}"
        else:
            return "å¯¹è¯å†å²ä¸å¤Ÿæ¸…æ™°ï¼Œéœ€è¦ä»åŸºç¡€å¼€å§‹äº†è§£ã€‚"
    
    def _extract_keywords_from_question(self, question: str) -> List[str]:
        """ä»é—®é¢˜ä¸­æå–å…³é”®è¯"""
        key_terms = ["æŠ€èƒ½", "é¡¹ç›®", "ç»éªŒ", "å·¥ä½œ", "å­¦ä¹ ", "æŒ‘æˆ˜", "å›¢é˜Ÿ", "æŠ€æœ¯"]
        return [term for term in key_terms if term in question]
    
    def _get_smart_interview_guidance(self, current_round: int, conversation_history: List, job_info: Dict) -> str:
        """æ™ºèƒ½ç”Ÿæˆé¢è¯•æŒ‡å¯¼å»ºè®®"""
        if current_round == 1:
            return "âš ï¸ è¿™æ˜¯ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œå¿…é¡»æ˜¯è‡ªæˆ‘ä»‹ç»ç›¸å…³çš„é—®é¢˜ï¼ä¸è¦é—®å…·ä½“çš„æŠ€æœ¯æˆ–é¡¹ç›®é—®é¢˜ã€‚"
        
        # åˆ†æå¯¹è¯å†å²ï¼Œåˆ¤æ–­æ˜¯å¦å·²ç»å……åˆ†éªŒè¯åŸºç¡€çŸ¥è¯†
        basic_knowledge_covered = self._analyze_basic_knowledge_coverage(conversation_history, job_info)
        project_questions_asked = self._analyze_project_questions_coverage(conversation_history)
        
        if not basic_knowledge_covered:
            return f"""
ğŸ¯ å½“å‰å»ºè®®ï¼šä¼˜å…ˆéªŒè¯åŸºç¡€ä¸“ä¸šçŸ¥è¯†
- é‡ç‚¹å…³æ³¨å²—ä½è¦æ±‚çš„æ ¸å¿ƒæŠ€èƒ½åŸºç¡€çŸ¥è¯†
- å…ˆç¡®ä¿å€™é€‰äººå…·å¤‡å¿…è¦çš„ç†è®ºåŸºç¡€
- æš‚æ—¶ä¸è¦æ·±å…¥é¡¹ç›®ç»†èŠ‚ï¼Œé™¤éå€™é€‰äººä¸»åŠ¨æåŠä¸”å›ç­”å……åˆ†
- å¯ä»¥é—®ä¸€äº›è¯¥å²—ä½å¿…é¡»æŒæ¡çš„åŸºæœ¬æ¦‚å¿µå’ŒæŠ€æœ¯åŸç†
"""
        elif not project_questions_asked:
            return f"""
âœ… åŸºç¡€çŸ¥è¯†éªŒè¯é˜¶æ®µå·²å®Œæˆï¼Œå»ºè®®è¿›å…¥é¡¹ç›®ç»éªŒé˜¶æ®µ
- å¯ä»¥å¼€å§‹æ·±å…¥äº†è§£å€™é€‰äººçš„é¡¹ç›®ç»éªŒ
- é‡ç‚¹è¯¢é—®é¡¹ç›®çš„æŠ€æœ¯å®ç°ç»†èŠ‚ã€é‡åˆ°çš„æŒ‘æˆ˜ã€è§£å†³æ–¹æ¡ˆ
- éªŒè¯ç†è®ºçŸ¥è¯†åœ¨å®é™…é¡¹ç›®ä¸­çš„åº”ç”¨èƒ½åŠ›
- äº†è§£å€™é€‰äººçš„å…·ä½“è´¡çŒ®å’ŒæŠ€æœ¯æˆé•¿
"""
        else:
            return f"""
ğŸ” è¿›å…¥æ·±åº¦è¯„ä¼°é˜¶æ®µ
- å¯ä»¥è€ƒå¯Ÿè§£å†³é—®é¢˜çš„æ€è·¯å’Œæ–¹æ³•
- äº†è§£å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”èƒ½åŠ›
- è¯„ä¼°æŠ€æœ¯è§†é‡å’Œå‘å±•æ½œåŠ›
- æˆ–è€…é’ˆå¯¹ä¹‹å‰å›ç­”ä¸å¤Ÿè¯¦ç»†çš„åœ°æ–¹è¿›è¡Œæ·±å…¥è¿½é—®
"""

    def _analyze_basic_knowledge_coverage(self, conversation_history: List, job_info: Dict) -> bool:
        """åˆ†ææ˜¯å¦å·²ç»å……åˆ†éªŒè¯äº†åŸºç¡€çŸ¥è¯†"""
        if not conversation_history or len(conversation_history) < 4:  # è‡³å°‘éœ€è¦2è½®é—®ç­”
            return False
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…æ¥åˆ¤æ–­æ˜¯å¦é—®è¿‡åŸºç¡€é—®é¢˜
        basic_keywords = ["ç®—æ³•", "æ•°æ®ç»“æ„", "åŸç†", "æ¦‚å¿µ", "åŸºç¡€", "ç†è®º", "å®šä¹‰", "åŒºåˆ«", "ä¼˜ç¼ºç‚¹"]
        
        questions_content = []
        for msg in conversation_history:
            if hasattr(msg, 'content'):
                questions_content.append(msg.content.lower())
        
        questions_text = " ".join(questions_content)
        basic_question_count = sum(1 for keyword in basic_keywords if keyword in questions_text)
        
        # å¦‚æœé—®è¿‡è‡³å°‘2ä¸ªåŸºç¡€é—®é¢˜ï¼Œè®¤ä¸ºåŸºç¡€çŸ¥è¯†éªŒè¯å·²ç»å¼€å§‹
        return basic_question_count >= 2

    def _analyze_project_questions_coverage(self, conversation_history: List) -> bool:
        """åˆ†ææ˜¯å¦å·²ç»é—®è¿‡é¡¹ç›®ç›¸å…³é—®é¢˜"""
        if not conversation_history:
            return False
        
        project_keywords = ["é¡¹ç›®", "å¼€å‘", "å®ç°", "æ¶æ„", "æŠ€æœ¯æ ˆ", "æŒ‘æˆ˜", "è§£å†³æ–¹æ¡ˆ", "ç»éªŒ"]
        
        questions_content = []
        for msg in conversation_history:
            if hasattr(msg, 'content'):
                questions_content.append(msg.content.lower())
        
        questions_text = " ".join(questions_content)
        project_question_count = sum(1 for keyword in project_keywords if keyword in questions_text)
        
        return project_question_count >= 2

    def _determine_interview_stage(self, current_round: int, conversation_history: List) -> str:
        """åˆ¤æ–­å½“å‰é¢è¯•é˜¶æ®µ"""
        if current_round == 1:
            return "å¼€åœºé˜¶æ®µ - è‡ªæˆ‘ä»‹ç»"
        elif current_round <= 3:
            return "åŸºç¡€çŸ¥è¯†éªŒè¯é˜¶æ®µ - äº†è§£ä¸“ä¸šåŸºç¡€"
        elif current_round <= 8:
            return "é¡¹ç›®ç»éªŒé˜¶æ®µ - æ·±å…¥äº†è§£å®è·µèƒ½åŠ›"
        else:
            return "æ·±åº¦è¯„ä¼°é˜¶æ®µ - ç»¼åˆèƒ½åŠ›è€ƒå¯Ÿ"
    
