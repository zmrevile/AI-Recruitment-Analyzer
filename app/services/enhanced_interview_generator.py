"""
æ™ºèƒ½é¢è¯•é—®é¢˜ç”Ÿæˆå™¨
å®Œå…¨åŸºäºæ˜Ÿç«å¤§æ¨¡å‹ï¼ŒåƒçœŸæ­£é¢è¯•å®˜ä¸€æ ·æ ¹æ®ç®€å†ã€å²—ä½è¦æ±‚å’Œå¯¹è¯å†å²åŠ¨æ€ç”Ÿæˆé—®é¢˜
"""
from typing import Dict, List, Optional
from app.core.spark_llm import SparkLLM
from langchain_core.messages import HumanMessage
from app.utils.json_helper import JSONHelper
import json
import re
from app.utils.logger import interview_generator_logger

class EnhancedInterviewGenerator:
    def __init__(self, spark_config: Dict):
        self.llm = SparkLLM(
            app_id=spark_config.get("app_id", ""),
            api_key=spark_config.get("api_key", ""),
            api_secret=spark_config.get("api_secret", ""),
            spark_url=spark_config.get("spark_url", "wss://spark-api.xf-yun.com/v3.5/chat"),
            domain=spark_config.get("domain", "generalv3.5"),
            temperature=0.7
        )
    

    

    
    def generate_next_question(self, candidate_info: Dict, job_info: Dict, 
                             conversation_history: List = None, 
                             current_round: int = 1,
                             resume_context: List[str] = None,
                             job_context: List[str] = None) -> Dict:
        """ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜"""
        prompt = self._build_interviewer_prompt(
            candidate_info, job_info, conversation_history, current_round,
            resume_context, job_context
        )
        
        print(f"ğŸ¤– é¢è¯•å®˜æ­£åœ¨æ€è€ƒç¬¬{current_round}ä¸ªé—®é¢˜...")
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        # ä½¿ç”¨ç»Ÿä¸€çš„JSONè§£ææ–¹æ³•
        question_data = JSONHelper.parse_llm_response(response.content, "é—®é¢˜ç”Ÿæˆ")
        
        if not question_data:
            raise ValueError(f"é—®é¢˜ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return question_data
    
    def should_follow_up(self, last_question: str, candidate_answer: str, 
                        resume_context: List[str] = None, 
                        job_context: List[str] = None) -> Dict:
        """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®"""
        prompt = self._build_follow_up_decision_prompt(
            last_question, candidate_answer, resume_context, job_context
        )
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        decision_data = JSONHelper.parse_llm_response(response.content, "è¿½é—®åˆ¤æ–­")
        
        if not decision_data:
            raise ValueError(f"è¿½é—®åˆ¤æ–­å¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return decision_data
    
    def generate_follow_up_question(self, last_question: str, candidate_answer: str,
                                   follow_up_focus: str, resume_context: List[str] = None,
                                   job_context: List[str] = None) -> Dict:
        """ç”Ÿæˆè¿½é—®é—®é¢˜"""
        prompt = self._build_follow_up_question_prompt(
            last_question, candidate_answer, follow_up_focus, resume_context, job_context
        )
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        question_data = JSONHelper.parse_llm_response(response.content, "è¿½é—®ç”Ÿæˆ")
        
        if not question_data:
            raise ValueError(f"è¿½é—®ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•è§£æå“åº”å†…å®¹ä¸ºæœ‰æ•ˆJSONæ ¼å¼")
        
        return question_data
    
    def _build_interviewer_prompt(self, candidate_info: Dict, job_info: Dict, 
                                 conversation_history: List, current_round: int,
                                 resume_context: List[str] = None,
                                 job_context: List[str] = None) -> str:
        """æ„å»ºé¢è¯•å®˜è§’è‰²æç¤ºè¯"""
        history_summary = self._summarize_conversation_history(conversation_history)
        interview_stage = self._determine_interview_stage(current_round, conversation_history)
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯é¢è¯•å®˜ï¼Œæ­£åœ¨é¢è¯•ä¸€ä½å€™é€‰äººã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜ï¼š

## å€™é€‰äººç®€å†ä¿¡æ¯ï¼š
{json.dumps(candidate_info, ensure_ascii=False, indent=2)}

## å²—ä½è¦æ±‚ï¼š
{json.dumps(job_info, ensure_ascii=False, indent=2)}

{context_info}

## é¢è¯•è¿›å±•ï¼š
- å½“å‰æ˜¯ç¬¬{current_round}ä¸ªé—®é¢˜
- é¢è¯•é˜¶æ®µï¼š{interview_stage}

## å¯¹è¯å†å²æ‘˜è¦ï¼š
{history_summary}

## é¢è¯•å®˜æŒ‡å¯¼åŸåˆ™ï¼š
1. **åˆ©ç”¨æ£€ç´¢ä¸Šä¸‹æ–‡**ï¼šä¼˜å…ˆåŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³ç®€å†ç‰‡æ®µå’Œå²—ä½è¦æ±‚è¿›è¡Œæé—®
2. **åƒçœŸæ­£é¢è¯•å®˜ä¸€æ ·æ€è€ƒ**ï¼šè€ƒè™‘å€™é€‰äººçš„èƒŒæ™¯ã€å²—ä½è¦æ±‚å’Œå·²ç»äº†è§£çš„ä¿¡æ¯
3. **å¾ªåºæ¸è¿›**ï¼šæ ¹æ®é¢è¯•é˜¶æ®µè°ƒæ•´é—®é¢˜æ·±åº¦å’Œç±»å‹
4. **æœ‰é’ˆå¯¹æ€§**ï¼šåŸºäºç®€å†äº®ç‚¹æˆ–æ½œåœ¨å…³æ³¨ç‚¹æé—®
5. **é¿å…é‡å¤**ï¼šä¸è¦é—®å·²ç»è®¨è®ºè¿‡çš„å†…å®¹
6. **è‡ªç„¶è¿‡æ¸¡**ï¼šé—®é¢˜è¦ç¬¦åˆé¢è¯•å¯¹è¯çš„è‡ªç„¶æµç¨‹
7. **æ·±åº¦æŒ–æ˜**ï¼šå¦‚æœæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ï¼Œè¦æ·±å…¥è¯¢é—®å…·ä½“ç»†èŠ‚

## é¢è¯•é˜¶æ®µç­–ç•¥ï¼š
- **å¼€åœºé˜¶æ®µ**(1è½®)ï¼šäº†è§£åŸºæœ¬æƒ…å†µï¼Œç¼“è§£ç´§å¼ æ„Ÿ
- **æŠ€èƒ½éªŒè¯**(2-6è½®)ï¼šæ·±å…¥äº†è§£æŠ€æœ¯èƒ½åŠ›å’Œé¡¹ç›®ç»éªŒ  
- **æ·±åº¦è¯„ä¼°**(7-10è½®)ï¼šè€ƒå¯Ÿæ€ç»´æ–¹å¼ã€è§£å†³é—®é¢˜èƒ½åŠ›
- **æ”¶å°¾é˜¶æ®µ**(10+è½®)ï¼šè¡¥å……äº†è§£ã€ç»™å€™é€‰äººæé—®æœºä¼š

è¯·ç›´æ¥è¿”å›çº¯JSONæ ¼å¼çš„é¢è¯•é—®é¢˜ï¼Œä¸è¦åŒ…å«ä»»ä½•ä»£ç å—æ ‡è®°ã€è§£é‡Šæˆ–æ€è€ƒè¿‡ç¨‹ï¼š

{{
    "type": "context_enhanced_question",
    "category": "é—®é¢˜ç±»åˆ«ï¼ˆå¦‚ï¼šæŠ€èƒ½éªŒè¯ã€é¡¹ç›®ç»éªŒã€æ€ç»´æ–¹å¼ç­‰ï¼‰",
    "question": "å…·ä½“é—®é¢˜å†…å®¹ï¼ˆè¦è‡ªç„¶ã€ä¸“ä¸šï¼Œä¼˜å…ˆåŸºäºæ£€ç´¢ä¸Šä¸‹æ–‡ï¼‰",
    "focus": "è€ƒå¯Ÿé‡ç‚¹",
    "expected_depth": "æœŸæœ›å›ç­”æ·±åº¦ï¼ˆbasic/medium/highï¼‰",
    "interviewer_thinking": "é¢è¯•å®˜çš„æ€è€ƒé€»è¾‘ï¼ˆä¸ºä»€ä¹ˆé—®è¿™ä¸ªé—®é¢˜ï¼‰",
    "context_used": "æ˜¯å¦ä½¿ç”¨äº†æ£€ç´¢ä¸Šä¸‹æ–‡ï¼ˆtrue/falseï¼‰"
}}
"""
    
    def _build_follow_up_decision_prompt(self, last_question: str, candidate_answer: str,
                                       resume_context: List[str] = None,
                                       job_context: List[str] = None) -> str:
        """æ„å»ºè¿½é—®åˆ¤æ–­æç¤ºè¯"""
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é¢è¯•å®˜ã€‚è¯·åˆ†æå€™é€‰äººçš„å›ç­”ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè¿½é—®ã€‚

é—®é¢˜ï¼š{last_question}

å€™é€‰äººå›ç­”ï¼š{candidate_answer}

{context_info}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®ï¼š

**éœ€è¦è¿½é—®çš„æƒ…å†µï¼š**
1. å›ç­”è¿‡äºç®€çŸ­æˆ–ç¬¼ç»Ÿï¼Œç¼ºä¹å…·ä½“ç»†èŠ‚
2. æåˆ°äº†æœ‰è¶£çš„æŠ€æœ¯ç‚¹ä½†æ²¡æœ‰æ·±å…¥è§£é‡Š
3. å›ç­”ä¸­æœ‰ä¸“ä¸šæœ¯è¯­ä½†æ²¡æœ‰å±•ç¤ºçœŸæ­£ç†è§£
4. æåˆ°äº†é¡¹ç›®æˆ–ç»éªŒä½†ç¼ºå°‘å…·ä½“æ•°æ®å’Œæˆæœ
5. å›ç­”ä¸ç®€å†ä¿¡æ¯ä¸ä¸€è‡´ï¼Œéœ€è¦æ¾„æ¸…
6. æ¶‰åŠå²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼Œå€¼å¾—æ·±å…¥äº†è§£

**ä¸éœ€è¦è¿½é—®çš„æƒ…å†µï¼š**
1. å›ç­”è¯¦ç»†å……åˆ†ï¼Œå·²ç»å±•ç¤ºäº†ç›¸å…³èƒ½åŠ›
2. å·²ç»è¿ç»­è¿½é—®2æ¬¡ä»¥ä¸ŠåŒä¸€è¯é¢˜
3. å›ç­”ä¸å²—ä½è¦æ±‚å…³è”åº¦è¾ƒä½
4. å€™é€‰äººæ˜æ˜¾å¯¹è¯¥è¯é¢˜ä¸ç†Ÿæ‚‰ï¼Œç»§ç»­è¿½é—®æ„ä¹‰ä¸å¤§
5. å€™é€‰äººä¸æƒ³å›ç­”è¿™ä¸ªé—®é¢˜

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "should_follow_up": true/false,
    "reason": "åˆ¤æ–­åŸå› ",
    "follow_up_focus": "å¦‚æœéœ€è¦è¿½é—®ï¼Œé‡ç‚¹å…³æ³¨ä»€ä¹ˆæ–¹é¢",
    "confidence": "high/medium/low",
    "suggested_direction": "å»ºè®®çš„è¿½é—®æ–¹å‘æˆ–ä¸‹ä¸€ä¸ªè¯é¢˜æ–¹å‘"
}}
"""
    
    def _build_follow_up_question_prompt(self, last_question: str, candidate_answer: str,
                                       follow_up_focus: str, resume_context: List[str] = None,
                                       job_context: List[str] = None) -> str:
        """æ„å»ºè¿½é—®é—®é¢˜æç¤ºè¯"""
        context_info = self._build_context_info(resume_context, job_context)
        
        return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é¢è¯•å®˜ï¼Œéœ€è¦åŸºäºå€™é€‰äººçš„å›ç­”ç”Ÿæˆä¸€ä¸ªç²¾å‡†çš„è¿½é—®ã€‚

åŸé—®é¢˜ï¼š{last_question}

å€™é€‰äººå›ç­”ï¼š{candidate_answer}

è¿½é—®é‡ç‚¹ï¼š{follow_up_focus}

{context_info}

è¯·ç”Ÿæˆä¸€ä¸ªè‡ªç„¶ã€æœ‰é’ˆå¯¹æ€§çš„è¿½é—®é—®é¢˜ï¼Œè¦æ±‚ï¼š
1. åŸºäºå€™é€‰äººåˆšæ‰çš„å›ç­”å†…å®¹
2. æŒ–æ˜æ›´æ·±å±‚çš„æŠ€æœ¯ç»†èŠ‚æˆ–å®è·µç»éªŒ
3. éªŒè¯å€™é€‰äººçš„çœŸå®ç†è§£ç¨‹åº¦
4. ä¿æŒé¢è¯•å¯¹è¯çš„è‡ªç„¶æµç•…
5. å¦‚æœæœ‰ç®€å†ä¿¡æ¯ï¼Œå¯ä»¥ç»“åˆç®€å†å†…å®¹è¿›è¡ŒéªŒè¯

è¿”å›JSONæ ¼å¼ï¼š
{{
    "type": "follow_up_question",
    "category": "è¿½é—®ç±»åˆ«",
    "question": "å…·ä½“çš„è¿½é—®é—®é¢˜",
    "focus": "è€ƒå¯Ÿé‡ç‚¹",
    "expected_depth": "æœŸæœ›å›ç­”æ·±åº¦ï¼ˆbasic/medium/highï¼‰",
    "interviewer_thinking": "é¢è¯•å®˜çš„æ€è€ƒé€»è¾‘",
    "follow_up_level": "ç¬¬å‡ å±‚è¿½é—®ï¼ˆfirst/second/thirdï¼‰"
}}
"""
    
    def _build_context_info(self, resume_context: List[str] = None, 
                           job_context: List[str] = None) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_info = ""
        if resume_context and len(resume_context) > 0:
            context_info += f"""
## ğŸ” ç›¸å…³ç®€å†ç‰‡æ®µï¼ˆåŸºäºå¯¹è¯æ£€ç´¢ï¼‰ï¼š
{chr(10).join([f"- {ctx}" for ctx in resume_context])}
"""
        
        if job_context and len(job_context) > 0:
            context_info += f"""
## ğŸ¯ ç›¸å…³å²—ä½è¦æ±‚ï¼ˆåŸºäºå¯¹è¯æ£€ç´¢ï¼‰ï¼š
{chr(10).join([f"- {ctx}" for ctx in job_context])}
"""
        return context_info
    
    def _summarize_conversation_history(self, conversation_history: List) -> str:
        """ç”Ÿæˆå¯¹è¯å†å²æ‘˜è¦"""
        if not conversation_history:
            return "è¿™æ˜¯é¢è¯•çš„å¼€å§‹ï¼Œè¿˜æ²¡æœ‰å¯¹è¯å†å²ã€‚"
        
        topics_discussed = []
        for item in conversation_history:
            if isinstance(item, dict):
                if "category" in item:
                    topics_discussed.append(item["category"])
                elif "question" in item:
                    keywords = self._extract_keywords_from_question(item["question"])
                    topics_discussed.extend(keywords)
        
        if topics_discussed:
            unique_topics = list(set(topics_discussed))
            return f"å·²ç»è®¨è®ºçš„è¯é¢˜ï¼š{', '.join(unique_topics[:5])}"
        else:
            return "å¯¹è¯å†å²ä¸å¤Ÿæ¸…æ™°ï¼Œéœ€è¦ä»åŸºç¡€å¼€å§‹äº†è§£ã€‚"
    
    def _extract_keywords_from_question(self, question: str) -> List[str]:
        """ä»é—®é¢˜ä¸­æå–å…³é”®è¯"""
        key_terms = ["æŠ€èƒ½", "é¡¹ç›®", "ç»éªŒ", "å·¥ä½œ", "å­¦ä¹ ", "æŒ‘æˆ˜", "å›¢é˜Ÿ", "æŠ€æœ¯"]
        return [term for term in key_terms if term in question]
    
    def _determine_interview_stage(self, current_round: int, conversation_history: List) -> str:
        """åˆ¤æ–­å½“å‰é¢è¯•é˜¶æ®µ"""
        stage_map = {
            (1, 1): "å¼€åœºé˜¶æ®µ - å»ºç«‹èæ´½å…³ç³»ï¼Œäº†è§£åŸºæœ¬æƒ…å†µ",
            (2, 6): "æŠ€èƒ½éªŒè¯é˜¶æ®µ - æ·±å…¥äº†è§£æŠ€æœ¯èƒ½åŠ›å’Œé¡¹ç›®ç»éªŒ",
            (7, 10): "æ·±åº¦è¯„ä¼°é˜¶æ®µ - è€ƒå¯Ÿæ€ç»´æ–¹å¼å’Œè§£å†³é—®é¢˜èƒ½åŠ›",
        }
        
        for (start, end), stage in stage_map.items():
            if start <= current_round <= end:
                return stage
        
        return "æ”¶å°¾é˜¶æ®µ - è¡¥å……äº†è§£ï¼Œå›ç­”å€™é€‰äººé—®é¢˜"
    
